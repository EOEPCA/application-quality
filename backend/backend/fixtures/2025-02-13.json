[
	{
		"model": "backend.pipeline",
		"pk": "new_pylint",
		"fields": {
			"description": "Another test pipeline that runs pylint with custom inputs",
			"template": "#!/usr/bin/env cwltool\r\n\r\n$graph:\r\n- class: Workflow\r\n\r\n  requirements:\r\n    SubworkflowFeatureRequirement: {}\r\n\r\n  inputs:\r\n    branch:\r\n      type: string\r\n      default: ''\r\n    pipeline_id: string\r\n    pylint_subworkflow_filter_regex:\r\n      label: regex\r\n      type: string\r\n      default: .*\r\n    pylint_subworkflow_pylint_disable:\r\n      label: disable\r\n      doc: |-\r\n        Disable the message, report, category or checker with the given id(s). You can either give multiple identifiers separated by comma (,) or put this option multiple times (only on the command line, not in the configuration file where it should appear only once). You can also use \"--disable=all\" to disable everything first and then re-enable specific checks. For example, if you want to run only the similarities checker, you can use \"--disable=all --enable=similarities\". If you want to run only the classes checker, but have no Warning level messages displayed, use \"--disable=all --enable=classes --disable=W\".\r\n      type: string\r\n      default: E0401\r\n    pylint_subworkflow_pylint_errors_only:\r\n      label: errors_only\r\n      doc: |-\r\n        In error mode, messages with a category besides ERROR or FATAL are suppressed, and no reports are done by default. Error mode is compatible with disabling specific errors.\r\n      type: boolean\r\n      default: false\r\n    pylint_subworkflow_pylint_verbose:\r\n      label: verbose\r\n      doc: In verbose mode, extra non-checker-related info will be displayed.\r\n      type: boolean\r\n      default: false\r\n    repo_url: string\r\n    run_id: string\r\n    server_url: string\r\n\r\n  outputs: []\r\n\r\n  steps:\r\n    clone_step:\r\n      in:\r\n        branch: branch\r\n        repo_url: repo_url\r\n      run: '#clone_tool'\r\n      out:\r\n      - repo_directory\r\n    {% for tool in subworkflows %}{{ tool.pipeline_step | indent(4) }}\r\n    {% endfor %}\r\n  id: main\r\n\r\n- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: alpine/git\r\n    InitialWorkDirRequirement:\r\n      listing:\r\n      - entryname: clone_branch.sh\r\n        entry: |-\r\n          set -e\r\n\r\n          if [ $(inputs.branch) ]; then\r\n            echo 'Branch specified: $(inputs.branch). Cloning branch...'\r\n            git clone $(inputs.repo_url) -b $(inputs.branch)\r\n          else\r\n            echo 'No branch specified. Cloning default branch...'\r\n            git clone $(inputs.repo_url)\r\n          fi\r\n\r\n          echo '✅ Cloned!\r\n          '\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    branch: string\r\n    repo_url: string\r\n\r\n  outputs:\r\n    repo_directory:\r\n      type: Directory\r\n      outputBinding:\r\n        glob: $(inputs.repo_url.split('/').pop().replace('.git',''))\r\n\r\n  baseCommand: sh\r\n  arguments:\r\n  - clone_branch.sh\r\n  id: clone_tool\r\n{% for tool in subworkflows %}\r\n{{ tool.definition }}\r\n{% endfor %}\r\ncwlVersion: v1.0",
			"owner": 1,
			"version": "0.1",
			"tools": [
				"new_pylint_workflow"
			]
		}
	},
	{
		"model": "backend.pipeline",
		"pk": "pylint_pipeline",
		"fields": {
			"description": "A test pipeline that runs pylint with custom inputs",
			"template": "#!/usr/bin/env cwltool\r\n\r\n$graph:\r\n- class: Workflow\r\n\r\n  requirements:\r\n    SubworkflowFeatureRequirement: {}\r\n\r\n  inputs:\r\n    branch:\r\n      type: string\r\n      default: ''\r\n    filter_regex:\r\n      type: string\r\n      default: '.*'\r\n    pipeline_id: string\r\n    pylint_errors_only: boolean\r\n    pylint_verbose: boolean\r\n    repo_url: string\r\n    run_id: string\r\n    server_url: string\r\n\r\n  outputs: []\r\n\r\n  steps:\r\n    clone_step:\r\n      in:\r\n        branch: branch\r\n        repo_url: repo_url\r\n      run: '#clone_tool'\r\n      out:\r\n      - repo_directory\r\n    {% for tool in subworkflows %}{{ tool.pipeline_step | indent(4) }}\r\n    {% endfor %}\r\n  id: main\r\n\r\n- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: alpine/git\r\n    InitialWorkDirRequirement:\r\n      listing:\r\n      - entryname: clone_branch.sh\r\n        entry: |-\r\n          set -e\r\n\r\n          if [ $(inputs.branch) ]; then\r\n            echo 'Branch specified: $(inputs.branch). Cloning branch...'\r\n            git clone $(inputs.repo_url) -b $(inputs.branch)\r\n          else\r\n            echo 'No branch specified. Cloning default branch...'\r\n            git clone $(inputs.repo_url)\r\n          fi\r\n\r\n          echo '✅ Cloned!\r\n          '\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    branch:\r\n      type: string\r\n      default: ''\r\n    repo_url: string\r\n\r\n  outputs:\r\n    repo_directory:\r\n      type: Directory\r\n      outputBinding:\r\n        glob: $(inputs.repo_url.split('/').pop().replace('.git',''))\r\n\r\n  baseCommand: sh\r\n  arguments:\r\n  - clone_branch.sh\r\n  id: clone_tool\r\n{% for tool in subworkflows %}\r\n{{ tool.definition }}\r\n{% endfor %}\r\ncwlVersion: v1.0",
			"owner": 1,
			"version": "0.1",
			"tools": [
				"pylint_parameters_workflow"
			]
		}
	},
	{
		"model": "backend.pipeline",
		"pk": "python",
		"fields": {
			"description": "python pipeline",
			"template": "#!/usr/bin/env cwltool\r\n\r\n$graph:\r\n- class: Workflow\r\n\r\n  requirements:\r\n    SubworkflowFeatureRequirement: {}\r\n\r\n  inputs:\r\n    pipeline_id:\r\n      type: string\r\n    repo_branch:\r\n      type: string\r\n    repo_url:\r\n      type: string\r\n    run_id:\r\n      type: string\r\n    server_url:\r\n      type: string\r\n\r\n  outputs: []\r\n\r\n  steps:\r\n    clone_step:\r\n      in:\r\n        repo_url: repo_url\r\n        repo_branch: repo_branch\r\n      run: '#clone_tool'\r\n      out:\r\n      - repo_directory\r\n    {% for tool in subworkflows %}{{ tool.pipeline_step | indent(4) }}\r\n    {% endfor %}\r\n  id: main\r\n\r\n- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: alpine/git\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    repo_branch:\r\n      type: string\r\n      default: main\r\n    repo_url:\r\n      type: string\r\n\r\n  outputs:\r\n    repo_directory:\r\n      type: Directory\r\n      outputBinding:\r\n        glob: $(inputs.repo_url.split('/').pop().replace('.git',''))\r\n\r\n  baseCommand: git\r\n  arguments:\r\n  - clone\r\n  - $(inputs.repo_url)\r\n  - -b\r\n  - $(inputs.repo_branch)\r\n  id: clone_tool\r\n{% for tool in subworkflows %}\r\n{{ tool.definition }}\r\n{% endfor %}\r\ncwlVersion: v1.0",
			"owner": null,
			"version": "0.1",
			"tools": [
				"bandit",
				"flake8",
				"pylint",
				"ruff"
			]
		}
	},
	{
		"model": "backend.pipeline",
		"pk": "sonarqube",
		"fields": {
			"description": "SonarQube pipeline",
			"template": "#!/usr/bin/env cwltool\r\n\r\n$graph:\r\n- class: Workflow\r\n\r\n  requirements:\r\n    SubworkflowFeatureRequirement: {}\r\n\r\n  inputs:\r\n    pipeline_id:\r\n      type: string\r\n    repo_branch:\r\n      type: string\r\n    repo_url:\r\n      type: string\r\n    run_id:\r\n      type: string\r\n    server_url:\r\n      type: string\r\n    sonarqube_project_key:\r\n      type: string\r\n    sonarqube_project_name:\r\n      type: string\r\n    sonarqube_server:\r\n      type: string\r\n      default: sonarqube-sonarqube.sonarqube:9000\r\n    sonarqube_token:\r\n      type: string\r\n\r\n  outputs: []\r\n\r\n  steps:\r\n    clone_step:\r\n      in:\r\n        repo_branch: repo_branch\r\n        repo_url: repo_url\r\n      run: '#clone_tool'\r\n      out:\r\n      - repo_directory\r\n    {% for tool in subworkflows %}{{ tool.pipeline_step | indent(4) }}\r\n    {% endfor %}\r\n  id: main\r\n- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: alpine/git\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    repo_branch:\r\n      type: string\r\n      default: main\r\n    repo_url:\r\n      type: string\r\n\r\n  outputs:\r\n    repo_directory:\r\n      type: Directory\r\n      outputBinding:\r\n        glob: $(inputs.repo_url.split('/').pop().replace('.git',''))\r\n\r\n  baseCommand: git\r\n  arguments:\r\n  - clone\r\n  - $(inputs.repo_url)\r\n  - -b\r\n  - $(inputs.repo_branch)\r\n  id: clone_tool\r\n{% for tool in subworkflows %}{{ tool.definition }}\r\n{% endfor %}\r\ncwlVersion: v1.0",
			"owner": null,
			"version": "0.1",
			"tools": [
				"sonarqube"
			]
		}
	},
	{
		"model": "backend.tag",
		"pk": 1,
		"fields": {
			"name": "python"
		}
	},
	{
		"model": "backend.tag",
		"pk": 2,
		"fields": {
			"name": "other"
		}
	},
	{
		"model": "backend.subworkflow",
		"pk": "bandit",
		"fields": {
			"name": "bandit",
			"description": "Bandit - Bandit is a tool designed to find common security issues in Python code",
			"pipeline_step": "bandit_workflow_step:\r\n  in:\r\n    pipeline_id: pipeline_id\r\n    repo_path: clone_step/repo_directory\r\n    run_id: run_id\r\n    server_url: server_url\r\n  run: '#bandit_workflow'\r\n  out: []",
			"definition": "- class: Workflow\r\n\r\n  inputs:\r\n    pipeline_id:\r\n      type: string\r\n    repo_path:\r\n      type: Directory\r\n    run_id:\r\n      type: string\r\n    server_url:\r\n      type: string\r\n    name:\r\n      type: string\r\n      default: bandit\r\n\r\n  outputs:\r\n    bandit_report:\r\n      type: File\r\n      outputSource: bandit_step/bandit_report\r\n\r\n  steps:\r\n    bandit_step:\r\n      in:\r\n        source_directory: repo_path\r\n      run: '#bandit_tool'\r\n      out:\r\n      - bandit_report\r\n    save_bandit_step:\r\n      in:\r\n        pipeline_id: pipeline_id\r\n        report: bandit_step/bandit_report\r\n        run_id: run_id\r\n        server_url: server_url\r\n        name: name\r\n      run: '#save_tool'\r\n      out: []\r\n  id: bandit_workflow\r\n{% for tool in tools %}{{ tool.definition }}\r\n{% endfor %}",
			"user_params": {},
			"version": "0.1",
			"tags": [
				1
			],
			"tools": [
				"bandit",
				"save"
			]
		}
	},
	{
		"model": "backend.subworkflow",
		"pk": "flake8",
		"fields": {
			"name": "flake8",
			"description": "flake8 - Style guide enforcement tool for Python",
			"pipeline_step": "flake8_workflow_step:\r\n  in:\r\n    pipeline_id: pipeline_id\r\n    repo_path: clone_step/repo_directory\r\n    run_id: run_id\r\n    server_url: server_url\r\n  run: '#flake8_workflow'\r\n  out: []",
			"definition": "- class: Workflow\r\n\r\n  inputs:\r\n    pipeline_id:\r\n      type: string\r\n    repo_path:\r\n      type: Directory\r\n    run_id:\r\n      type: string\r\n    server_url:\r\n      type: string\r\n    name:\r\n      type: string\r\n      default: flake8\r\n\r\n  outputs:\r\n    flake8_report:\r\n      type: File\r\n      outputSource: flake8_step/flake8_report\r\n\r\n  steps:\r\n    flake8_step:\r\n      in:\r\n        source_directory: repo_path\r\n      run: '#flake8_tool'\r\n      out:\r\n      - flake8_report\r\n    save_flake8_step:\r\n      in:\r\n        pipeline_id: pipeline_id\r\n        report: flake8_step/flake8_report\r\n        run_id: run_id\r\n        server_url: server_url\r\n        name: name\r\n      run: '#save_tool'\r\n      out: []\r\n  id: flake8_workflow\r\n{% for tool in tools %}{{ tool.definition }}\r\n{% endfor %}",
			"user_params": {},
			"version": "0.1",
			"tags": [
				1
			],
			"tools": [
				"flake8",
				"save"
			]
		}
	},
	{
		"model": "backend.subworkflow",
		"pk": "new_pylint_workflow",
		"fields": {
			"name": "pylint new",
			"description": "Another pylint subworkflow with customizable parameters",
			"pipeline_step": "pylint_subworkflow:\r\n  in:\r\n    filter_regex: pylint_subworkflow_filter_regex\r\n    pipeline_id: pipeline_id\r\n    pylint_disable: pylint_subworkflow_pylint_disable\r\n    pylint_errors_only: pylint_subworkflow_pylint_errors_only\r\n    pylint_verbose: pylint_subworkflow_pylint_verbose\r\n    run_id: run_id\r\n    server_url: server_url\r\n    source_directory: clone_step/repo_directory\r\n  run: '#pylint_subworkflow'\r\n  out: []",
			"definition": "- class: Workflow\r\n\r\n  inputs:\r\n    name:\r\n      type: string\r\n      default: pylint_new\r\n    filter_regex: string\r\n    pipeline_id: string\r\n    pylint_disable: string\r\n    pylint_errors_only: boolean\r\n    pylint_verbose: boolean\r\n    run_id: string\r\n    server_url: string\r\n    source_directory: Directory\r\n\r\n  outputs: []\r\n\r\n  steps:\r\n    filter_step:\r\n      in:\r\n        regex: filter_regex\r\n        source_directory: source_directory\r\n      run: '#filter_tool'\r\n      out:\r\n      - file_list\r\n    pylint_step:\r\n      in:\r\n        disable: pylint_disable\r\n        errors_only: pylint_errors_only\r\n        file_list: filter_step/file_list\r\n        source_directory: source_directory\r\n        verbose: pylint_verbose\r\n      run: '#pylint_tool_parameters'\r\n      out:\r\n      - pylint_report\r\n    save_step:\r\n      in:\r\n        name: name\r\n        pipeline_id: pipeline_id\r\n        report: pylint_step/pylint_report\r\n        run_id: run_id\r\n        server_url: server_url\r\n      run: '#save_tool'\r\n      out: []\r\n  id: pylint_subworkflow\r\n{% for tool in tools %}{{ tool.definition }}\r\n{% endfor %}",
			"user_params": {
				"filter": {
					"regex": {
						"type": "string",
						"label": "regex",
						"default": ".*"
					}
				},
				"pylint": {
					"disable": {
						"doc": "Disable the message, report, category or checker with the given id(s). You can either give multiple identifiers separated by comma (,) or put this option multiple times (only on the command line, not in the configuration file where it should appear only once). You can also use \"--disable=all\" to disable everything first and then re-enable specific checks. For example, if you want to run only the similarities checker, you can use \"--disable=all --enable=similarities\". If you want to run only the classes checker, but have no Warning level messages displayed, use \"--disable=all --enable=classes --disable=W\".",
						"type": "string",
						"label": "disable",
						"default": "E0401"
					},
					"verbose": {
						"doc": "In verbose mode, extra non-checker-related info will be displayed.",
						"type": "bool",
						"label": "verbose",
						"default": false
					},
					"errors_only": {
						"doc": "In error mode, messages with a category besides ERROR or FATAL are suppressed, and no reports are done by default. Error mode is compatible with disabling specific errors.",
						"type": "bool",
						"label": "errors_only",
						"default": false
					}
				}
			},
			"version": "0.1",
			"tags": [
				1
			],
			"tools": [
				"filter",
				"new_pylint",
				"save"
			]
		}
	},
	{
		"model": "backend.subworkflow",
		"pk": "pylint",
		"fields": {
			"name": "pylint",
			"description": "pylint - Static code analyser tool for Python",
			"pipeline_step": "pylint_workflow_step:\r\n  in:\r\n    pipeline_id: pipeline_id\r\n    repo_path: clone_step/repo_directory\r\n    run_id: run_id\r\n    server_url: server_url\r\n  run: '#pylint_workflow'\r\n  out: []",
			"definition": "- class: Workflow\r\n\r\n  inputs:\r\n    pipeline_id:\r\n      type: string\r\n    repo_path:\r\n      type: Directory\r\n    run_id:\r\n      type: string\r\n    server_url:\r\n      type: string\r\n    name:\r\n      type: string\r\n      default: pylint\r\n\r\n  outputs:\r\n    pylint_report:\r\n      type: File\r\n      outputSource: pylint_step/pylint_report\r\n\r\n  steps:\r\n    pylint_step:\r\n      in:\r\n        source_directory: repo_path\r\n      run: '#pylint_tool'\r\n      out:\r\n      - pylint_report\r\n    save_pylint_step:\r\n      in:\r\n        pipeline_id: pipeline_id\r\n        report: pylint_step/pylint_report\r\n        run_id: run_id\r\n        server_url: server_url\r\n        name: name\r\n      run: '#save_tool'\r\n      out: []\r\n  id: pylint_workflow\r\n{% for tool in tools %}{{ tool.definition }}\r\n{% endfor %}",
			"user_params": {},
			"version": "0.1",
			"tags": [
				1
			],
			"tools": [
				"pylint",
				"save"
			]
		}
	},
	{
		"model": "backend.subworkflow",
		"pk": "pylint_parameters_workflow",
		"fields": {
			"name": "pylint with parameters",
			"description": "A pylint subworkflow with customizable parameters",
			"pipeline_step": "pylint_subworkflow:\r\n  in:\r\n    errors_only: pylint_errors_only\r\n    pipeline_id: pipeline_id\r\n    regex: filter_regex\r\n    run_id: run_id\r\n    server_url: server_url\r\n    source_directory: clone_step/repo_directory\r\n    verbose: pylint_verbose\r\n  run: '#pylint_subworkflow'\r\n  out: []",
			"definition": "- class: Workflow\r\n\r\n  inputs:\r\n    name:\r\n      type: string\r\n      default: pylint_parameters\r\n    errors_only: boolean\r\n    pipeline_id: string\r\n    regex: string\r\n    run_id: string\r\n    server_url: string\r\n    source_directory: Directory\r\n    verbose: boolean\r\n\r\n  outputs: []\r\n\r\n  steps:\r\n    filter_step:\r\n      in:\r\n        regex: regex\r\n        source_directory: source_directory\r\n      run: '#filter_tool'\r\n      out:\r\n      - file_list\r\n    pylint_step:\r\n      in:\r\n        errors_only: errors_only\r\n        file_list: filter_step/file_list\r\n        source_directory: source_directory\r\n        verbose: verbose\r\n      run: '#pylint_tool_parameters'\r\n      out:\r\n      - pylint_report\r\n    save_step:\r\n      in:\r\n        name: name\r\n        pipeline_id: pipeline_id\r\n        report: pylint_step/pylint_report\r\n        run_id: run_id\r\n        server_url: server_url\r\n      run: '#save_tool'\r\n      out: []\r\n  id: pylint_subworkflow\r\n{% for tool in tools %}{{ tool.definition }}\r\n{% endfor %}",
			"user_params": {
				"verbose": {
					"doc": "In verbose mode, extra non-checker-related info will be displayed.",
					"type": "bool",
					"default": false
				},
				"errors_only": {
					"doc": "In error mode, messages with a category besides ERROR or FATAL are suppressed, and no reports are done by default. Error mode is compatible with disabling specific errors.",
					"type": "bool",
					"default": false
				}
			},
			"version": "0.1",
			"tags": [
				1
			],
			"tools": [
				"filter",
				"pylint_parameters",
				"save"
			]
		}
	},
	{
		"model": "backend.subworkflow",
		"pk": "ruff",
		"fields": {
			"name": "ruff",
			"description": "Ruff - An extremely fast Python linter and code formatter, written in Rust",
			"pipeline_step": "ruff_workflow_step:\r\n  in:\r\n    pipeline_id: pipeline_id\r\n    repo_path: clone_step/repo_directory\r\n    run_id: run_id\r\n    server_url: server_url\r\n  run: '#ruff_workflow'\r\n  out: []",
			"definition": "- class: Workflow\r\n\r\n  inputs:\r\n    pipeline_id:\r\n      type: string\r\n    repo_path:\r\n      type: Directory\r\n    run_id:\r\n      type: string\r\n    server_url:\r\n      type: string\r\n    name:\r\n      type: string\r\n      default: ruff\r\n\r\n  outputs:\r\n    ruff_report:\r\n      type: File\r\n      outputSource: ruff_step/ruff_report\r\n\r\n  steps:\r\n    ruff_step:\r\n      in:\r\n        source_directory: repo_path\r\n      run: '#ruff_tool'\r\n      out:\r\n      - ruff_report\r\n    save_ruff_step:\r\n      in:\r\n        pipeline_id: pipeline_id\r\n        report: ruff_step/ruff_report\r\n        run_id: run_id\r\n        server_url: server_url\r\n        name: name\r\n      run: '#save_tool'\r\n      out: []\r\n  id: ruff_workflow\r\n{% for tool in tools %}{{ tool.definition }}\r\n{% endfor %}",
			"user_params": {},
			"version": "0.1",
			"tags": [
				1
			],
			"tools": [
				"ruff",
				"save"
			]
		}
	},
	{
		"model": "backend.subworkflow",
		"pk": "sonarqube",
		"fields": {
			"name": "sonarqube",
			"description": "SonarQube - Code Quality, Security & Static Analysis Tool\r\n\r\nThis tool creates a project in our internal SonarQube server, sends it the code for analysis, and then retrieves the analysis results for storage in the database.",
			"pipeline_step": "sonarqube_workflow_step:\r\n  in:\r\n    pipeline_id: pipeline_id\r\n    repo_path: clone_step/repo_directory\r\n    run_id: run_id\r\n    server_url: server_url\r\n    sonarqube_project_key: sonarqube_project_key\r\n    sonarqube_project_name: sonarqube_project_name\r\n    sonarqube_server: sonarqube_server\r\n    sonarqube_token: sonarqube_token\r\n  run: '#sonarqube_workflow'\r\n  out: []",
			"definition": "- class: Workflow\r\n\r\n  inputs:\r\n    name:\r\n      type: string\r\n      default: sonarqube\r\n    pipeline_id:\r\n      type: string\r\n    repo_path:\r\n      type: Directory\r\n    run_id:\r\n      type: string\r\n    server_url:\r\n      type: string\r\n    sonarqube_project_key:\r\n      type: string\r\n    sonarqube_project_name:\r\n      type: string\r\n    sonarqube_server:\r\n      type: string\r\n      default: sonarqube-sonarqube.sonarqube:9000\r\n    sonarqube_token:\r\n      type: string\r\n\r\n  outputs: []\r\n\r\n  steps:\r\n    save_sonarqube_step:\r\n      in:\r\n        name: name\r\n        pipeline_id: pipeline_id\r\n        report: sonarqube_get_report_step/sonarqube_report\r\n        run_id: run_id\r\n        server_url: server_url\r\n      run: '#save_tool'\r\n      out: []\r\n    sonarqube_create_project_step:\r\n      in:\r\n        sonarqube_project_key: sonarqube_project_key\r\n        sonarqube_project_name: sonarqube_project_name\r\n        sonarqube_server: sonarqube_server\r\n        sonarqube_token: sonarqube_token\r\n      run: '#sonarqube_create_project_tool'\r\n      out:\r\n      - sonarqube_project_key\r\n      - sonarqube_server\r\n      - sonarqube_token\r\n    sonarqube_get_report_step:\r\n      in:\r\n        sonarqube_project_key: sonarqube_scan_step/sonarqube_project_key\r\n        sonarqube_server: sonarqube_scan_step/sonarqube_server\r\n        sonarqube_token: sonarqube_scan_step/sonarqube_token\r\n      run: '#sonarqube_get_report_tool'\r\n      out:\r\n      - sonarqube_project_key\r\n      - sonarqube_server\r\n      - sonarqube_token\r\n      - sonarqube_report\r\n    sonarqube_scan_step:\r\n      in:\r\n        sonarqube_project_key: sonarqube_create_project_step/sonarqube_project_key\r\n        sonarqube_server: sonarqube_create_project_step/sonarqube_server\r\n        sonarqube_token: sonarqube_create_project_step/sonarqube_token\r\n        source_directory: repo_path\r\n      run: '#sonarqube_scan_tool'\r\n      out:\r\n      - sonarqube_project_key\r\n      - sonarqube_server\r\n      - sonarqube_token\r\n  id: sonarqube_workflow\r\n{% for tool in tools %}{{ tool.definition }}\r\n{% endfor %}",
			"user_params": {},
			"version": "0.1",
			"tags": [],
			"tools": [
				"save",
				"sonarqube_create_project",
				"sonarqube_get_report",
				"sonarqube_scan"
			]
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "bandit",
		"fields": {
			"name": "bandit",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: cytopia/bandit\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    source_directory:\r\n      type: Directory\r\n      inputBinding:\r\n        position: 1\r\n\r\n  outputs:\r\n    bandit_report:\r\n      type: File\r\n      outputBinding:\r\n        glob: bandit_report.json\r\n\r\n  baseCommand:\r\n  - bandit\r\n  arguments:\r\n  - -x\r\n  - .git\r\n  - -f\r\n  - json\r\n  - -o\r\n  - bandit_report.json\r\n  - --exit-zero\r\n  id: bandit_tool",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "filter",
		"fields": {
			"name": "filter",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: alpine:latest\r\n    InitialWorkDirRequirement:\r\n      listing:\r\n      - entryname: filter_script.sh\r\n        entry: |-\r\n          cd $(inputs.source_directory.path)\r\n          find . -type f -regex \"$(inputs.regex)\" > $HOME/filter.out\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    regex:\r\n      type: string\r\n      default: '.*'\r\n    source_directory: Directory\r\n\r\n  outputs:\r\n    file_list:\r\n      type: string[]\r\n      outputBinding:\r\n        glob: filter.out\r\n        outputEval: $(self[0].contents.split('\\n').filter(line => line.trim() !== ''))\r\n        loadContents: true\r\n\r\n  baseCommand: sh\r\n  arguments:\r\n  - filter_script.sh\r\n  id: filter_tool",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "flake8",
		"fields": {
			"name": "flake8",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: eoepca/appquality-flake8-json:v0.1.0\r\n\r\n  inputs:\r\n    source_directory:\r\n      type: Directory\r\n      inputBinding:\r\n        position: 1\r\n\r\n  outputs:\r\n    flake8_report:\r\n      type: File\r\n      outputBinding:\r\n        glob: flake8_report.json\r\n\r\n  baseCommand: flake8\r\n  arguments:\r\n  - --format=json\r\n  - --output-file=flake8_report.json\r\n  id: flake8_tool",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "new_pylint",
		"fields": {
			"name": "pylint new",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: cytopia/pylint\r\n    InitialWorkDirRequirement:\r\n      listing:\r\n      - entryname: pylint_script.sh\r\n        entry: |-\r\n          cd $(inputs.source_directory.path)\r\n\r\n          PARAMS=\"--output-format=$(inputs.output_format) --output=$HOME/$(inputs.output_file) --disable=$(inputs.disable)\"\r\n          if [ \"$(inputs.exit_zero)\" == \"true\" ] ; then\r\n            PARAMS=\"$PARAMS --exit-zero\"\r\n          fi\r\n          if [ \"$(inputs.errors_only)\" == \"true\" ] ; then\r\n            PARAMS=\"$PARAMS -E\"\r\n          fi\r\n          if [ \"$(inputs.verbose)\" == \"true\" ] ; then\r\n            PARAMS=\"$PARAMS -v\"\r\n          fi\r\n\r\n          pylint $PARAMS $(inputs.file_list.join(\" \"))\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    disable: string\r\n    errors_only: boolean\r\n    exit_zero:\r\n      doc: |-\r\n        Always return a 0 (non-error) status code, even if lint errors are found. This is primarily useful in continuous integration scripts.\r\n      type: boolean\r\n      default: true\r\n    file_list: string[]\r\n    output_file:\r\n      doc: Specify an output file.\r\n      type: string\r\n      default: pylint_report.json\r\n    output_format:\r\n      doc: |-\r\n        Set the output format. Available formats are: text, parseable, colorized, json2 (improved json format), json (old json format) and msvs (visual studio). You can also give a reporter class, e.g. mypackage.mymodule.MyReporterClass.\r\n      type: string\r\n      default: json\r\n    source_directory: Directory\r\n    verbose: boolean\r\n\r\n  outputs:\r\n    pylint_report:\r\n      type: File\r\n      outputBinding:\r\n        glob: $(inputs.output_file)\r\n\r\n  baseCommand: sh\r\n  arguments:\r\n  - pylint_script.sh\r\n  id: pylint_tool_parameters",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "pylint",
		"fields": {
			"name": "pylint",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: cytopia/pylint\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    source_directory:\r\n      type: Directory\r\n      inputBinding:\r\n        position: 1\r\n        valueFrom: $(inputs.source_directory.path + \"/**/*.py\")\r\n\r\n  outputs:\r\n    pylint_report:\r\n      type: File\r\n      outputBinding:\r\n        glob: pylint_report.json\r\n\r\n  baseCommand: pylint\r\n  arguments:\r\n  - --output-format=json\r\n  - --output=pylint_report.json\r\n  - --exit-zero\r\n  id: pylint_tool",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "pylint_parameters",
		"fields": {
			"name": "pylint with parameters",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: cytopia/pylint\r\n    InitialWorkDirRequirement:\r\n      listing:\r\n      - entryname: pylint_script.sh\r\n        entry: |-\r\n          cd $(inputs.source_directory.path)\r\n\r\n          PARAMS=\"--output-format=$(inputs.output_format) --output=$HOME/$(inputs.output_file) --disable=$(inputs.disable)\"\r\n          if [ \"$(inputs.exit_zero)\" == \"true\" ] ; then\r\n            PARAMS=\"$PARAMS --exit-zero\"\r\n          fi\r\n          if [ \"$(inputs.errors_only)\" == \"true\" ] ; then\r\n            PARAMS=\"$PARAMS -E\"\r\n          fi\r\n          if [ \"$(inputs.verbose)\" == \"true\" ] ; then\r\n            PARAMS=\"$PARAMS -v\"\r\n          fi\r\n\r\n          pylint $PARAMS $(inputs.file_list.join(\" \"))\r\n\r\n          exit 0\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    disable:\r\n      doc: |-\r\n        Disable the message, report, category or checker with the given id(s). You can either give multiple identifiers separated by comma (,) or put this option multiple times (only on the command line, not in the configuration file where it should appear only once). You can also use \"--disable=all\" to disable everything first and then re-enable specific checks. For example, if you want to run only the similarities checker, you can use \"--disable=all --enable=similarities\". If you want to run only the classes checker, but have no Warning level messages displayed, use \"--disable=all --enable=classes --disable=W\".\r\n      type: string\r\n      default: E0401\r\n    errors_only:\r\n      doc: |-\r\n        In error mode, messages with a category besides ERROR or FATAL are suppressed, and no reports are done by default. Error mode is compatible with disabling specific errors.\r\n      type: boolean\r\n      default: false\r\n    exit_zero:\r\n      doc: |-\r\n        Always return a 0 (non-error) status code, even if lint errors are found. This is primarily useful in continuous integration scripts.\r\n      type: boolean\r\n      default: true\r\n    file_list: string[]\r\n    output_file:\r\n      doc: Specify an output file.\r\n      type: string\r\n      default: pylint_report.json\r\n    output_format:\r\n      doc: |-\r\n        Set the output format. Available formats are: text, parseable, colorized, json2 (improved json format), json (old json format) and msvs (visual studio). You can also give a reporter class, e.g. mypackage.mymodule.MyReporterClass.\r\n      type: string\r\n      default: json\r\n    source_directory: Directory\r\n    verbose:\r\n      doc: In verbose mode, extra non-checker-related info will be displayed.\r\n      type: boolean\r\n      default: false\r\n\r\n  outputs:\r\n    pylint_report:\r\n      type: File\r\n      outputBinding:\r\n        glob: $(inputs.output_file)\r\n\r\n  baseCommand: sh\r\n  arguments:\r\n  - pylint_script.sh\r\n  id: pylint_tool_parameters",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "ruff",
		"fields": {
			"name": "ruff",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: ghcr.io/astral-sh/ruff:alpine\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    source_directory:\r\n      type: Directory\r\n      inputBinding:\r\n        position: 1\r\n\r\n  outputs:\r\n    ruff_report:\r\n      type: File\r\n      outputBinding:\r\n        glob: ruff_report.json\r\n\r\n  baseCommand:\r\n  - ruff\r\n  - check\r\n  arguments:\r\n  - --exclude\r\n  - .git\r\n  - --output-format\r\n  - json\r\n  - -o\r\n  - ruff_report.json\r\n  - -en\r\n  id: ruff_tool",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "save",
		"fields": {
			"name": "save",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: curlimages/curl\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    name:\r\n      type: string\r\n    pipeline_id:\r\n      type: string\r\n    report:\r\n      type: File\r\n    run_id:\r\n      type: string\r\n    server_url:\r\n      type: string\r\n\r\n  outputs: []\r\n\r\n  baseCommand: curl\r\n  arguments:\r\n  - prefix: -X\r\n    valueFrom: POST\r\n  - prefix: -L\r\n    valueFrom: |-\r\n      $('http://' + inputs.server_url + '/api/pipelines/' + inputs.pipeline_id + '/runs/' + inputs.run_id + '/jobreports/?name=' + inputs.name)\r\n  - prefix: -H\r\n    valueFrom: Content-Type:application/json\r\n  - prefix: -d\r\n    valueFrom: $('@' + inputs.report.path)\r\n  id: save_tool",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "sonarqube_create_project",
		"fields": {
			"name": "[sonarqube] create project",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: curlimages/curl\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    sonarqube_project_key:\r\n      type: string\r\n    sonarqube_project_name:\r\n      type: string\r\n    sonarqube_server:\r\n      type: string\r\n      default: sonarqube-sonarqube.sonarqube:9000\r\n    sonarqube_token:\r\n      type: string\r\n\r\n  outputs:\r\n    sonarqube_project_key:\r\n      type: string\r\n      outputBinding:\r\n        outputEval: $(inputs.sonarqube_project_key)\r\n    sonarqube_server:\r\n      type: string\r\n      outputBinding:\r\n        outputEval: $(inputs.sonarqube_server)\r\n    sonarqube_token:\r\n      type: string\r\n      outputBinding:\r\n        outputEval: $(inputs.sonarqube_token)\r\n\r\n  baseCommand:\r\n  - curl\r\n  arguments:\r\n  - prefix: -X\r\n    valueFrom: POST\r\n  - prefix: -L\r\n    valueFrom: $('http://' + inputs.sonarqube_server + '/api/projects/create')\r\n  - prefix: -u\r\n    valueFrom: $(inputs.sonarqube_token + ':')\r\n  - prefix: -d\r\n    valueFrom: $('name=' + inputs.sonarqube_project_name)\r\n  - prefix: -d\r\n    valueFrom: $('project=' + inputs.sonarqube_project_key)\r\n  id: sonarqube_create_project_tool",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "sonarqube_get_report",
		"fields": {
			"name": "[sonarqube] get report",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: curlimages/curl\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    sonarqube_project_key:\r\n      type: string\r\n    sonarqube_server:\r\n      type: string\r\n      default: sonarqube-sonarqube.sonarqube:9000\r\n    sonarqube_token:\r\n      type: string\r\n\r\n  outputs:\r\n    sonarqube_project_key:\r\n      type: string\r\n      outputBinding:\r\n        outputEval: $(inputs.sonarqube_project_key)\r\n    sonarqube_report:\r\n      type: File\r\n      outputBinding:\r\n        glob: sonarqube_report.json\r\n    sonarqube_server:\r\n      type: string\r\n      outputBinding:\r\n        outputEval: $(inputs.sonarqube_server)\r\n    sonarqube_token:\r\n      type: string\r\n      outputBinding:\r\n        outputEval: $(inputs.sonarqube_token)\r\n  stdout: sonarqube_report.json\r\n\r\n  baseCommand:\r\n  - curl\r\n  arguments:\r\n  - prefix: -L\r\n    valueFrom: |-\r\n      $('http://' + inputs.sonarqube_server + '/api/issues/search?components=' + inputs.sonarqube_project_key)\r\n  - prefix: -u\r\n    valueFrom: $(inputs.sonarqube_token + ':')\r\n  id: sonarqube_get_report_tool",
			"version": "0.1"
		}
	},
	{
		"model": "backend.commandlinetool",
		"pk": "sonarqube_scan",
		"fields": {
			"name": "[sonarqube] scan",
			"definition": "- class: CommandLineTool\r\n\r\n  requirements:\r\n    DockerRequirement:\r\n      dockerPull: sonarsource/sonar-scanner-cli\r\n    EnvVarRequirement:\r\n      envDef:\r\n        SONAR_HOST_URL: $('http://' + inputs.sonarqube_server)\r\n        SONAR_TOKEN: $(inputs.sonarqube_token)\r\n    InlineJavascriptRequirement: {}\r\n\r\n  inputs:\r\n    sonarqube_project_key:\r\n      type: string\r\n    sonarqube_server:\r\n      type: string\r\n      default: sonarqube-sonarqube.sonarqube:9000\r\n    sonarqube_token:\r\n      type: string\r\n    source_directory:\r\n      type: Directory\r\n\r\n  outputs:\r\n    sonarqube_project_key:\r\n      type: string\r\n      outputBinding:\r\n        glob:\r\n        outputEval: $(inputs.sonarqube_project_key)\r\n    sonarqube_server:\r\n      type: string\r\n      outputBinding:\r\n        glob:\r\n        outputEval: $(inputs.sonarqube_server)\r\n    sonarqube_token:\r\n      type: string\r\n      outputBinding:\r\n        glob:\r\n        outputEval: $(inputs.sonarqube_token)\r\n\r\n  baseCommand:\r\n  - sonar-scanner\r\n  arguments:\r\n  - prefix: -D\r\n    valueFrom: $('sonar.projectKey=' + inputs.sonarqube_project_key)\r\n    separate: false\r\n  # - prefix: -D\r\n  #   valueFrom: $('sonar.userHome=$HOME')\r\n  #   separate: false\r\n  - prefix: -D\r\n    valueFrom: $('sonar.projectBaseDir=' + inputs.source_directory.path + '/../')\r\n    separate: false\r\n  # - prefix: -D\r\n  #   valueFrom: $('sonar.source=$HOME' /*+ inputs.source_directory.path*/)\r\n  #   separate: false\r\n  - prefix: -X\r\n  id: sonarqube_scan_tool",
			"version": "0.1"
		}
	}
]